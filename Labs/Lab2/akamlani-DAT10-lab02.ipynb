{
 "metadata": {
  "name": "",
  "signature": "sha256:0b8515f05e182cfe136b98187b1f850af8a7b0e8c9a285d9c0fcde863e55de76"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# GA Data Science 10 (DAT5) - Lab2\n",
      "\n",
      "### Importing Data - JSON, CSVs, APIs\n",
      "\n",
      "Craig Sakuma\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Last time we covered introductions to: \n",
      "- #### Python \n",
      "- #### iPython Notebooks\n",
      "- #### numpy  \n",
      "- #### Pandas\n",
      "\n",
      "#### Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Agenda\n",
      "\n",
      "1. JSON\n",
      "2. API "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. JSON"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "- What's Json? (and why do we care?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the homework data into a pandas dataset\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv(\"titanic-train.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# assign the first 5 rows to a variable called first\n",
      "\n",
      "first = data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use the DataFrame method to_json to transform <first> into a json object\n",
      "first.to_json()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'{\"PassengerId\":{\"0\":1,\"1\":2,\"2\":3,\"3\":4,\"4\":5},\"Survived\":{\"0\":0,\"1\":1,\"2\":1,\"3\":1,\"4\":0},\"Pclass\":{\"0\":3,\"1\":1,\"2\":3,\"3\":1,\"4\":3},\"Name\":{\"0\":\"Braund, Mr. Owen Harris\",\"1\":\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",\"2\":\"Heikkinen, Miss. Laina\",\"3\":\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",\"4\":\"Allen, Mr. William Henry\"},\"Sex\":{\"0\":\"male\",\"1\":\"female\",\"2\":\"female\",\"3\":\"female\",\"4\":\"male\"},\"Age\":{\"0\":22.0,\"1\":38.0,\"2\":26.0,\"3\":35.0,\"4\":35.0},\"SibSp\":{\"0\":1,\"1\":1,\"2\":0,\"3\":1,\"4\":0},\"Parch\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Ticket\":{\"0\":\"A\\\\/5 21171\",\"1\":\"PC 17599\",\"2\":\"STON\\\\/O2. 3101282\",\"3\":\"113803\",\"4\":\"373450\"},\"Fare\":{\"0\":7.25,\"1\":71.2833,\"2\":7.925,\"3\":53.1,\"4\":8.05},\"Cabin\":{\"0\":null,\"1\":\"C85\",\"2\":null,\"3\":\"C123\",\"4\":null},\"Embarked\":{\"0\":\"S\",\"1\":\"C\",\"2\":\"S\",\"3\":\"S\",\"4\":\"S\"}}'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# explore the different options in the to_json method\n",
      "first.to_json(orient = 'records')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "'[{\"PassengerId\":1,\"Survived\":0,\"Pclass\":3,\"Name\":\"Braund, Mr. Owen Harris\",\"Sex\":\"male\",\"Age\":22.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"A\\\\/5 21171\",\"Fare\":7.25,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":2,\"Survived\":1,\"Pclass\":1,\"Name\":\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",\"Sex\":\"female\",\"Age\":38.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"PC 17599\",\"Fare\":71.2833,\"Cabin\":\"C85\",\"Embarked\":\"C\"},{\"PassengerId\":3,\"Survived\":1,\"Pclass\":3,\"Name\":\"Heikkinen, Miss. Laina\",\"Sex\":\"female\",\"Age\":26.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"STON\\\\/O2. 3101282\",\"Fare\":7.925,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":4,\"Survived\":1,\"Pclass\":1,\"Name\":\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",\"Sex\":\"female\",\"Age\":35.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"113803\",\"Fare\":53.1,\"Cabin\":\"C123\",\"Embarked\":\"S\"},{\"PassengerId\":5,\"Survived\":0,\"Pclass\":3,\"Name\":\"Allen, Mr. William Henry\",\"Sex\":\"male\",\"Age\":35.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"373450\",\"Fare\":8.05,\"Cabin\":null,\"Embarked\":\"S\"}]'"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. APIs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- What's an API? (and why do we care?)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.a A simple web request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "\n",
      "def get_historical_prices(symbol, start_date, end_date):\n",
      "    \"\"\"\n",
      "    Get historical prices for the given ticker symbol.\n",
      "    Date format is 'YYYYMMDD'\n",
      "    \n",
      "    Returns a json list.\n",
      "    \"\"\"\n",
      "    url = 'http://ichart.yahoo.com/table.csv?s=%s&' % symbol + \\\n",
      "          'd=%s&' % str(int(end_date[4:6]) - 1) + \\\n",
      "          'e=%s&' % str(int(end_date[6:8])) + \\\n",
      "          'f=%s&' % str(int(end_date[0:4])) + \\\n",
      "          'g=d&' + \\\n",
      "          'a=%s&' % str(int(start_date[4:6]) - 1) + \\\n",
      "          'b=%s&' % str(int(start_date[6:8])) + \\\n",
      "          'c=%s&' % str(int(start_date[0:4])) + \\\n",
      "          'ignore=.csv'\n",
      "    days = urllib.urlopen(url).readlines()\n",
      "    data = [day[:-2].split(',') for day in days]\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_historical_prices('GOOGL', '20140101', '20140106')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Clos'],\n",
        " ['2014-01-06',\n",
        "  '1113.01',\n",
        "  '1118.86',\n",
        "  '1106.44',\n",
        "  '1117.32',\n",
        "  '3535000',\n",
        "  '559.2'],\n",
        " ['2014-01-03',\n",
        "  '1115.00',\n",
        "  '1116.93',\n",
        "  '1104.93',\n",
        "  '1105.00',\n",
        "  '3330000',\n",
        "  '553.0'],\n",
        " ['2014-01-02',\n",
        "  '1115.46',\n",
        "  '1117.75',\n",
        "  '1108.26',\n",
        "  '1113.12',\n",
        "  '3639100',\n",
        "  '557.1']]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obtain the prices of Yahoo for the past month and insert them in a Pandas Dataframe\n",
      "\n",
      "prices =get_historical_prices('YHOO', '20140217', '20140317')\n",
      "\n",
      "df = pd.DataFrame(prices[1:], columns= prices[0], dtype=int).set_index('Date')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Open</th>\n",
        "      <th>High</th>\n",
        "      <th>Low</th>\n",
        "      <th>Close</th>\n",
        "      <th>Volume</th>\n",
        "      <th>Adj Clos</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-03-17</th>\n",
        "      <td> 39.00</td>\n",
        "      <td> 39.36</td>\n",
        "      <td> 38.61</td>\n",
        "      <td> 39.11</td>\n",
        "      <td> 29698300</td>\n",
        "      <td> 39.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-14</th>\n",
        "      <td> 36.69</td>\n",
        "      <td> 38.19</td>\n",
        "      <td> 36.45</td>\n",
        "      <td> 37.60</td>\n",
        "      <td> 30862300</td>\n",
        "      <td> 37.6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-13</th>\n",
        "      <td> 38.05</td>\n",
        "      <td> 38.42</td>\n",
        "      <td> 36.81</td>\n",
        "      <td> 37.23</td>\n",
        "      <td> 21179700</td>\n",
        "      <td> 37.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-12</th>\n",
        "      <td> 37.21</td>\n",
        "      <td> 37.61</td>\n",
        "      <td> 36.48</td>\n",
        "      <td> 37.50</td>\n",
        "      <td> 14794700</td>\n",
        "      <td> 37.5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-11</th>\n",
        "      <td> 38.25</td>\n",
        "      <td> 38.30</td>\n",
        "      <td> 37.43</td>\n",
        "      <td> 37.56</td>\n",
        "      <td> 12592300</td>\n",
        "      <td> 37.5</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "             Open   High    Low  Close    Volume Adj Clos\n",
        "Date                                                     \n",
        "2014-03-17  39.00  39.36  38.61  39.11  29698300     39.1\n",
        "2014-03-14  36.69  38.19  36.45  37.60  30862300     37.6\n",
        "2014-03-13  38.05  38.42  36.81  37.23  21179700     37.2\n",
        "2014-03-12  37.21  37.61  36.48  37.50  14794700     37.5\n",
        "2014-03-11  38.25  38.30  37.43  37.56  12592300     37.5"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 20 entries, 2014-03-17 to 2014-02-18\n",
        "Data columns (total 6 columns):\n",
        "Open        20 non-null object\n",
        "High        20 non-null object\n",
        "Low         20 non-null object\n",
        "Close       20 non-null object\n",
        "Volume      20 non-null int64\n",
        "Adj Clos    20 non-null object\n",
        "dtypes: int64(1), object(5)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1\n",
      "##### Create a pandas dataframe with all the stock price data for Alibaba (BABA)\n",
      "##### What was the highest trading price of the Alibaba stock?\n",
      "##### What was the lowest trading price of the Alibaba stock?\n",
      "\n",
      "#### Hint: Look in pandas documentation or stackoverflow\n",
      "\n",
      "### Bonus Question\n",
      "##### What were the Yahoo highs and lows for the same days as the Alibaba highs and lows?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get price data for Alibaba\n",
      "baba_data = get_historical_prices('BABA', '20140101', '20141006')\n",
      "dfb = pd.DataFrame(baba_data[1:], columns= baba_data[0], dtype=int).set_index('Date')\n",
      "dfb.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Open</th>\n",
        "      <th>High</th>\n",
        "      <th>Low</th>\n",
        "      <th>Close</th>\n",
        "      <th>Volume</th>\n",
        "      <th>Adj Clos</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-10-06</th>\n",
        "      <td> 89.15</td>\n",
        "      <td> 89.65</td>\n",
        "      <td> 88.06</td>\n",
        "      <td> 88.31</td>\n",
        "      <td>  9268400</td>\n",
        "      <td> 88.3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-10-03</th>\n",
        "      <td> 88.10</td>\n",
        "      <td> 89.94</td>\n",
        "      <td> 87.65</td>\n",
        "      <td> 88.10</td>\n",
        "      <td> 18485700</td>\n",
        "      <td> 88.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-10-02</th>\n",
        "      <td> 86.27</td>\n",
        "      <td> 88.20</td>\n",
        "      <td> 85.61</td>\n",
        "      <td> 87.06</td>\n",
        "      <td> 21469700</td>\n",
        "      <td> 87.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-10-01</th>\n",
        "      <td> 88.70</td>\n",
        "      <td> 88.94</td>\n",
        "      <td> 86.04</td>\n",
        "      <td> 86.10</td>\n",
        "      <td> 24029600</td>\n",
        "      <td> 86.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-09-30</th>\n",
        "      <td> 89.00</td>\n",
        "      <td> 90.88</td>\n",
        "      <td> 88.46</td>\n",
        "      <td> 88.85</td>\n",
        "      <td> 24419400</td>\n",
        "      <td> 88.8</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "             Open   High    Low  Close    Volume Adj Clos\n",
        "Date                                                     \n",
        "2014-10-06  89.15  89.65  88.06  88.31   9268400     88.3\n",
        "2014-10-03  88.10  89.94  87.65  88.10  18485700     88.1\n",
        "2014-10-02  86.27  88.20  85.61  87.06  21469700     87.0\n",
        "2014-10-01  88.70  88.94  86.04  86.10  24029600     86.1\n",
        "2014-09-30  89.00  90.88  88.46  88.85  24419400     88.8"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get max and min trading price\n",
      "dfb[\"High\"].max(), dfb[\"Low\"].min()\n",
      "# dfb.describe().loc['min']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "('99.70', '85.61')"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# bonus question\n",
      "# get days of \n",
      "baba_maxi_date = dfb.index[dfb.Low == dfb.Low.max()]\n",
      "baba_mini_date = dfb.index[dfb.Low == dfb.Low.min()]\n",
      "baba_maxi_date[0], baba_mini_date[0] \n",
      "\n",
      "prices = get_historical_prices('YHOO', '20140217', '20141010')\n",
      "df = pd.DataFrame(prices[1:], columns= prices[0], dtype=int).set_index('Date')\n",
      "# list all the keys: df.keys()\n",
      "# get data for max and min data from alliba \n",
      "print df[(baba_maxi_date[0] == df.index) == True]\n",
      "print df[(baba_mini_date[0] == df.index) == True]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             Open   High    Low  Close     Volume Adj Clos\n",
        "Date                                                      \n",
        "2014-09-19  42.44  43.19  39.55  40.93  233687300     40.9\n",
        "             Open   High    Low  Close    Volume Adj Clos\n",
        "Date                                                     \n",
        "2014-10-02  40.24  40.64  39.69  40.50  24584400     40.5\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.b Unstructured data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#### HTTP requests can be handled easily using Python's `requests` library.\n",
      "\n",
      "First we will load our credentials which we keep in a [YAML](http://www.yaml.org/) file for safe keeping."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import yaml\n",
      "#credentials = yaml.load(open('/users/Craig_Sakuma/api_cred.yml'))\n",
      "credentials = yaml.load(open('/home/akamlani/projects/datascience/classes/ga/ds/api_cred.yml'))\n",
      "credentials"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "{'CONSUMER_KEY': 'L1qJw4txKn44GS8rGdHtaP4Vo',\n",
        " 'CONSUMER_SECRET': 'sfgzoA2xKdGQZKHuRBwlAsVxsIwyxTP1lmc2wfF3pt7OuimWYC',\n",
        " 'OAUTH_TOKEN': '14204136-RAmAQ7yzzzOf7rVYoAnoWIgiUISU4h6zcP6SOxtMY',\n",
        " 'OAUTH_TOKEN_SECRET': 'kbRFD5SjkoefZhywfwYSGIqQtzu3hidulRVukeAxe6Bsx',\n",
        " 'PASS': 'calidawg01',\n",
        " 'USER': 'akamlani',\n",
        " 'kimono_key': '1nN1KEVUtMwhkB3PR3pTZcIY7ngd5WHE'}"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Then we pass those credentials in to a GET request using the requests library. In this case, I am querying my own user data from Github:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "r = requests.get('https://api.github.com/user', \n",
      "                 auth=(credentials['USER'], credentials['PASS']))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Requests gives us an object from which we can read its content."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.content"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'{\"login\":\"akamlani\",\"id\":1408490,\"avatar_url\":\"https://avatars.githubusercontent.com/u/1408490?v=2\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/akamlani\",\"html_url\":\"https://github.com/akamlani\",\"followers_url\":\"https://api.github.com/users/akamlani/followers\",\"following_url\":\"https://api.github.com/users/akamlani/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/akamlani/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/akamlani/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/akamlani/subscriptions\",\"organizations_url\":\"https://api.github.com/users/akamlani/orgs\",\"repos_url\":\"https://api.github.com/users/akamlani/repos\",\"events_url\":\"https://api.github.com/users/akamlani/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/akamlani/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"Ari Kamlani\",\"company\":\"\",\"blog\":\"http://arikamlani.com\",\"location\":\"San Francisco\",\"email\":\"akamlani@gmail.com\",\"hireable\":false,\"bio\":null,\"public_repos\":9,\"public_gists\":0,\"followers\":0,\"following\":11,\"created_at\":\"2012-02-04T18:29:35Z\",\"updated_at\":\"2014-10-09T03:22:53Z\",\"private_gists\":0,\"total_private_repos\":0,\"owned_private_repos\":0,\"disk_usage\":164500,\"collaborators\":0,\"plan\":{\"name\":\"free\",\"space\":307200,\"collaborators\":0,\"private_repos\":0}}'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "#### One of the reasons we like JSON is that it is easy to transform into a Python `dict` object using the `json` library:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "user = json.loads(r.content)\n",
      "user"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "{u'avatar_url': u'https://avatars.githubusercontent.com/u/1408490?v=2',\n",
        " u'bio': None,\n",
        " u'blog': u'http://arikamlani.com',\n",
        " u'collaborators': 0,\n",
        " u'company': u'',\n",
        " u'created_at': u'2012-02-04T18:29:35Z',\n",
        " u'disk_usage': 164500,\n",
        " u'email': u'akamlani@gmail.com',\n",
        " u'events_url': u'https://api.github.com/users/akamlani/events{/privacy}',\n",
        " u'followers': 0,\n",
        " u'followers_url': u'https://api.github.com/users/akamlani/followers',\n",
        " u'following': 11,\n",
        " u'following_url': u'https://api.github.com/users/akamlani/following{/other_user}',\n",
        " u'gists_url': u'https://api.github.com/users/akamlani/gists{/gist_id}',\n",
        " u'gravatar_id': u'',\n",
        " u'hireable': False,\n",
        " u'html_url': u'https://github.com/akamlani',\n",
        " u'id': 1408490,\n",
        " u'location': u'San Francisco',\n",
        " u'login': u'akamlani',\n",
        " u'name': u'Ari Kamlani',\n",
        " u'organizations_url': u'https://api.github.com/users/akamlani/orgs',\n",
        " u'owned_private_repos': 0,\n",
        " u'plan': {u'collaborators': 0,\n",
        "  u'name': u'free',\n",
        "  u'private_repos': 0,\n",
        "  u'space': 307200},\n",
        " u'private_gists': 0,\n",
        " u'public_gists': 0,\n",
        " u'public_repos': 9,\n",
        " u'received_events_url': u'https://api.github.com/users/akamlani/received_events',\n",
        " u'repos_url': u'https://api.github.com/users/akamlani/repos',\n",
        " u'site_admin': False,\n",
        " u'starred_url': u'https://api.github.com/users/akamlani/starred{/owner}{/repo}',\n",
        " u'subscriptions_url': u'https://api.github.com/users/akamlani/subscriptions',\n",
        " u'total_private_repos': 0,\n",
        " u'type': u'User',\n",
        " u'updated_at': u'2014-10-09T03:22:53Z',\n",
        " u'url': u'https://api.github.com/users/akamlani'}"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print user.keys()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'disk_usage', u'private_gists', u'public_repos', u'site_admin', u'subscriptions_url', u'gravatar_id', u'hireable', u'id', u'followers_url', u'following_url', u'collaborators', u'total_private_repos', u'blog', u'followers', u'location', u'type', u'email', u'bio', u'gists_url', u'owned_private_repos', u'company', u'events_url', u'html_url', u'updated_at', u'plan', u'received_events_url', u'starred_url', u'public_gists', u'name', u'organizations_url', u'url', u'created_at', u'avatar_url', u'repos_url', u'following', u'login']\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "We can access values in this dict directly (such as my hireable status) and even render the url of my avatar:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "print \"Hireable: {}\".format(user.get('hireable'))\n",
      "HTML('<img src={} />'.format(user.get('avatar_url')))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Hireable: False\n"
       ]
      },
      {
       "html": [
        "<img src=https://avatars.githubusercontent.com/u/1408490?v=2 />"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "<IPython.core.display.HTML at 0x7f0d6a158c50>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Twitter API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Twitter has no less than 10 python libraries. We'll be using Python Twitter Tools because it's what's used in Mining the Social Web."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "#### Some services (like Twitter) have released Python libraries of their own to make using their API even easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "auth = twitter.oauth.OAuth(credentials['OAUTH_TOKEN'], \n",
      "                           credentials['OAUTH_TOKEN_SECRET'],\n",
      "                           credentials['CONSUMER_KEY'],\n",
      "                           credentials['CONSUMER_SECRET'])\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<twitter.api.Twitter object at 0x7f0d6a09bc50>\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "#### Using a library like this, we don't even need to specify the URL (that's handled internally)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Using a library like this, it's easy to do something like search for tweets mentioning `#bigdata`  \n",
      "\n",
      "The results are transformed into a Python object (which in this case is a thin wrapper around a `dict`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigdata = twitter_api.search.tweets(q='#bigdata', count=5)\n",
      "type(bigdata)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "twitter.api.TwitterDictResponse"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for status in bigdata['statuses']:\n",
      "    print status.get('text')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RT @siprasad: Salesforce Makes Its Big Data Move - New York Times (blog) http://t.co/UqKRu5Anh7 #BigData\n",
        "RT @avdingus: Introducing #Wave, the #AnalyticsCloud from @Salesforce: #SFDC Makes Its #BigData Move http://t.co/Emfw5WwiFC via @nytimesbits\n",
        "RT @JohndeVoogd: Could big-data analytics improve federal procurement? -- FCW http://t.co/5KHI47MiuC  #bigdata\n",
        "RT @BigDataNewsco: #BigData #Analytics @SocialNewsCorp http://t.co/nEUF4WgtZZ Via #Twitter @drs_ch @noopnup @sehau_\n",
        "#NowPlaying on Genzel Radio: #BigData - Dangerous (feat. Joywave) #hits #edm #hiphop #tfb http://t.co/5wEtFOoT4J\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Twitter lab\n",
      "[http://tinyurl.com/GAtwitterlab](http://nbviewer.ipython.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%201%20-%20Mining%20Twitter.ipynb) up through Exercise 5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Useful links:\n",
      "\n",
      "[Mining the Social Web](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied (use --upgrade to upgrade): twitter in /opt/anaconda/lib/python2.7/site-packages\r\n",
        "Cleaning up...\r\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create your own Twitter credentials:\n",
      "\n",
      "#### Step 1:\n",
      "Go to https://dev.twitter.com/apps and sign in.\n",
      "\n",
      "#### Step 2:\n",
      "Register an application (doesn't have to be real, just a placeholder)\n",
      "\n",
      "Website: http://example.com\n",
      "\n",
      "Callback URL: http://example.com/auth/twitter/callback/\n",
      "\n",
      "#### Step 3:\n",
      "Add api key and api secret to your yaml file\n",
      "\n",
      "#### Step 4:\n",
      "Click on generate token and add information into your yaml file\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create your own yaml file called api_cred.yml \n",
      "Use the credential_example.yml file as a template"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#credentials = yaml.load(open('/users/Craig_Sakuma/api_cred.yml'))\n",
      "credentials = yaml.load(open('/home/akamlani/projects/datascience/classes/ga/ds/api_cred.yml'))\n",
      "auth = twitter.oauth.OAuth(credentials['OAUTH_TOKEN'], \n",
      "                           credentials['OAUTH_TOKEN_SECRET'],\n",
      "                           credentials['CONSUMER_KEY'],\n",
      "                           credentials['CONSUMER_SECRET'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "# Nothing to see by displaying twitter_api except that it's now a\n",
      "# defined variable\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<twitter.api.Twitter object at 0x7f0d6aed6990>\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
      "# http://developer.yahoo.com/geo/geoplanet/\n",
      "\n",
      "WORLD_WOE_ID = 1\n",
      "US_WOE_ID = 23424977\n",
      "\n",
      "# Prefix ID with the underscore for query string parameterization.\n",
      "# Without the underscore, the twitter package appends the ID value\n",
      "# to the URL itself as a special case keyword argument.\n",
      "\n",
      "world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID)\n",
      "us_trends = twitter_api.trends.place(_id=US_WOE_ID)\n",
      "\n",
      "print world_trends\n",
      "print\n",
      "print us_trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{u'created_at': u'2014-10-13T01:24:17Z', u'trends': [{u'url': u'http://twitter.com/search?q=%23myTWD', u'query': u'%23myTWD', u'name': u'#myTWD', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23InCarolWeTrust', u'query': u'%23InCarolWeTrust', u'name': u'#InCarolWeTrust', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23TheWalkingDeadTONIGHT', u'query': u'%23TheWalkingDeadTONIGHT', u'name': u'#TheWalkingDeadTONIGHT', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23TresPalabras', u'query': u'%23TresPalabras', u'name': u'#TresPalabras', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Go+Carol%22', u'query': u'%22Go+Carol%22', u'name': u'Go Carol', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23TWDReturns', u'query': u'%23TWDReturns', u'name': u'#TWDReturns', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Foles+to+Casey%22', u'query': u'%22Foles+to+Casey%22', u'name': u'Foles to Casey', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Tyreese', u'query': u'Tyreese', u'name': u'Tyreese', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Basta+de+Ponzio%22', u'query': u'%22Basta+de+Ponzio%22', u'name': u'Basta de Ponzio', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Terminus', u'query': u'Terminus', u'name': u'Terminus', u'promoted_content': None}], u'as_of': u'2014-10-13T01:27:31Z', u'locations': [{u'woeid': 1, u'name': u'Worldwide'}]}]\n",
        "\n",
        "[{u'created_at': u'2014-10-13T01:21:09Z', u'trends': [{u'url': u'http://twitter.com/search?q=%23TheWalkingDeadTONIGHT', u'query': u'%23TheWalkingDeadTONIGHT', u'name': u'#TheWalkingDeadTONIGHT', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Tyreese', u'query': u'Tyreese', u'name': u'Tyreese', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Judith', u'query': u'Judith', u'name': u'Judith', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23Season5Premiere', u'query': u'%23Season5Premiere', u'name': u'#Season5Premiere', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23ripmitchelmusso', u'query': u'%23ripmitchelmusso', u'name': u'#ripmitchelmusso', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23TeamCarol', u'query': u'%23TeamCarol', u'name': u'#TeamCarol', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23NYGvsPHI', u'query': u'%23NYGvsPHI', u'name': u'#NYGvsPHI', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Casey+Matthews%22', u'query': u'%22Casey+Matthews%22', u'name': u'Casey Matthews', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Terminus', u'query': u'Terminus', u'name': u'Terminus', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Bennie+Logan%22', u'query': u'%22Bennie+Logan%22', u'name': u'Bennie Logan', u'promoted_content': None}], u'as_of': u'2014-10-13T01:27:32Z', u'locations': [{u'woeid': 23424977, u'name': u'United States'}]}]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "print json.dumps(world_trends, indent=1)\n",
      "print\n",
      "print json.dumps(us_trends, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\n",
        " {\n",
        "  \"created_at\": \"2014-10-13T01:24:17Z\", \n",
        "  \"trends\": [\n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23myTWD\", \n",
        "    \"query\": \"%23myTWD\", \n",
        "    \"name\": \"#myTWD\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23InCarolWeTrust\", \n",
        "    \"query\": \"%23InCarolWeTrust\", \n",
        "    \"name\": \"#InCarolWeTrust\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23TheWalkingDeadTONIGHT\", \n",
        "    \"query\": \"%23TheWalkingDeadTONIGHT\", \n",
        "    \"name\": \"#TheWalkingDeadTONIGHT\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23TresPalabras\", \n",
        "    \"query\": \"%23TresPalabras\", \n",
        "    \"name\": \"#TresPalabras\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Go+Carol%22\", \n",
        "    \"query\": \"%22Go+Carol%22\", \n",
        "    \"name\": \"Go Carol\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23TWDReturns\", \n",
        "    \"query\": \"%23TWDReturns\", \n",
        "    \"name\": \"#TWDReturns\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Foles+to+Casey%22\", \n",
        "    \"query\": \"%22Foles+to+Casey%22\", \n",
        "    \"name\": \"Foles to Casey\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Tyreese\", \n",
        "    \"query\": \"Tyreese\", \n",
        "    \"name\": \"Tyreese\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Basta+de+Ponzio%22\", \n",
        "    \"query\": \"%22Basta+de+Ponzio%22\", \n",
        "    \"name\": \"Basta de Ponzio\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Terminus\", \n",
        "    \"query\": \"Terminus\", \n",
        "    \"name\": \"Terminus\", \n",
        "    \"promoted_content\": null\n",
        "   }\n",
        "  ], \n",
        "  \"as_of\": \"2014-10-13T01:27:31Z\", \n",
        "  \"locations\": [\n",
        "   {\n",
        "    \"woeid\": 1, \n",
        "    \"name\": \"Worldwide\"\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "]\n",
        "\n",
        "[\n",
        " {\n",
        "  \"created_at\": \"2014-10-13T01:21:09Z\", \n",
        "  \"trends\": [\n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23TheWalkingDeadTONIGHT\", \n",
        "    \"query\": \"%23TheWalkingDeadTONIGHT\", \n",
        "    \"name\": \"#TheWalkingDeadTONIGHT\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Tyreese\", \n",
        "    \"query\": \"Tyreese\", \n",
        "    \"name\": \"Tyreese\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Judith\", \n",
        "    \"query\": \"Judith\", \n",
        "    \"name\": \"Judith\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23Season5Premiere\", \n",
        "    \"query\": \"%23Season5Premiere\", \n",
        "    \"name\": \"#Season5Premiere\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23ripmitchelmusso\", \n",
        "    \"query\": \"%23ripmitchelmusso\", \n",
        "    \"name\": \"#ripmitchelmusso\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23TeamCarol\", \n",
        "    \"query\": \"%23TeamCarol\", \n",
        "    \"name\": \"#TeamCarol\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23NYGvsPHI\", \n",
        "    \"query\": \"%23NYGvsPHI\", \n",
        "    \"name\": \"#NYGvsPHI\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Casey+Matthews%22\", \n",
        "    \"query\": \"%22Casey+Matthews%22\", \n",
        "    \"name\": \"Casey Matthews\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Terminus\", \n",
        "    \"query\": \"Terminus\", \n",
        "    \"name\": \"Terminus\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Bennie+Logan%22\", \n",
        "    \"query\": \"%22Bennie+Logan%22\", \n",
        "    \"name\": \"Bennie Logan\", \n",
        "    \"promoted_content\": null\n",
        "   }\n",
        "  ], \n",
        "  \"as_of\": \"2014-10-13T01:27:32Z\", \n",
        "  \"locations\": [\n",
        "   {\n",
        "    \"woeid\": 23424977, \n",
        "    \"name\": \"United States\"\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "world_trends_set = set([trend['name'] \n",
      "                        for trend in world_trends[0]['trends']])\n",
      "\n",
      "us_trends_set = set([trend['name'] \n",
      "                     for trend in us_trends[0]['trends']]) \n",
      "\n",
      "common_trends = world_trends_set.intersection(us_trends_set)\n",
      "\n",
      "print common_trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set([u'Tyreese', u'Terminus', u'#TheWalkingDeadTONIGHT'])\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q = '#DataScience' \n",
      "\n",
      "count = 100\n",
      "\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
      "\n",
      "search_results = twitter_api.search.tweets(q=q, count=count)\n",
      "\n",
      "statuses = search_results['statuses']\n",
      "\n",
      "# print json.dumps(search_results, indent=1)\n",
      "# print json.dumps(statuses, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "status_texts = [ status['text'] \n",
      "                 for status in statuses ]\n",
      "\n",
      "screen_names = [ user_mention['screen_name'] \n",
      "                 for status in statuses\n",
      "                     for user_mention in status['entities']['user_mentions'] ]\n",
      "\n",
      "hashtags = [ hashtag['text'] \n",
      "             for status in statuses\n",
      "                 for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "# Compute a collection of all words from all tweets\n",
      "words = [ w \n",
      "          for t in status_texts \n",
      "              for w in t.split() ]\n",
      "\n",
      "# Explore the first 5 items for each...\n",
      "#print json.dumps(status_texts[0:5], indent=1)\n",
      "#print json.dumps(screen_names[0:5], indent=1) \n",
      "#print json.dumps(hashtags[0:5], indent=1)\n",
      "#print json.dumps(words[0:5], indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "for item in [words, screen_names, hashtags]:\n",
      "    c = Counter(item)\n",
      "    print c.most_common()[:10] # top 10\n",
      "    print\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'RT', 78), (u'#DataScience', 43), (u'#datascience', 40), (u'#BigData', 30), (u'the', 28), (u'in', 22), (u'and', 20), (u'#bigdata', 20), (u'Data', 18), (u'via', 17)]\n",
        "\n",
        "[(u'tonyojeda3', 14), (u'KirkDBorne', 13), (u'AngelaZutavern', 9), (u'verge', 8), (u'EdwardTufte', 8), (u'kdnuggets', 7), (u'mjcavaretta', 6), (u'sehau_', 5), (u'AnalyticsInst', 4), (u'wonkydata', 4)]\n",
        "\n",
        "[(u'DataScience', 60), (u'datascience', 40), (u'BigData', 34), (u'bigdata', 20), (u'Analytics', 14), (u'design', 9), (u'visualization', 9), (u'UX', 9), (u'rstats', 5), (u'KDD', 3)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 2\n",
      "##### What are the search results for #machinelearning?\n",
      "##### Which words, screen_names and hashtags are most common?\n",
      "\n",
      "### Bonus Questions\n",
      "##### Which hashtags are most common between #machinelearning and #datascience?\n",
      "##### Search the most popular data science hashtags and determine what topics are trending the most across the most popular data science hastags?\n",
      "##### Determine the most prolific screen_names for data science and find out who they are?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# search results for #machinelearning\n",
      "# type(ml); twitter.api.TwitterDictResponse\n",
      "ml = twitter_api.search.tweets(q='#machinelearning', count=100)\n",
      "ml_statuses = ml['statuses']\n",
      "#print json.dumps(ml_statuses, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# most popular screen_names, hashtags, status_texts\n",
      "ml_screen_names = [ user_mention['screen_name'] \n",
      "                    for status in ml_statuses\n",
      "                        for user_mention in status['entities']['user_mentions'] ]\n",
      "\n",
      "ml_hashtags = [ hashtag['text'] \n",
      "                for status in ml_statuses\n",
      "                    for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "ml_status_texts = [ status['text'] \n",
      "                    for status in ml_statuses ]\n",
      "ml_words = [ w \n",
      "             for t in ml_status_texts\n",
      "                 for w in t.split() ]\n",
      "\n",
      "\n",
      "from collections import Counter\n",
      "for item in [ml_words, ml_screen_names, ml_hashtags]:\n",
      "    cml = Counter(item)\n",
      "    print cml.most_common()[:10] # top 10\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'#machinelearning', 59), (u'RT', 54), (u'#MachineLearning', 36), (u'with', 22), (u'the', 18), (u'in', 17), (u'by', 17), (u'and', 16), (u'#bigdata', 16), (u'@KirkDBorne:', 16)]\n",
        "\n",
        "[(u'KirkDBorne', 18), (u'hexadata', 13), (u'ArnoCandel', 9), (u'Wikipedia', 7), (u'Datumbox', 7), (u'mbgrw', 6), (u'SumAllOrg', 4), (u'HNTracker', 4), (u'kasshout', 3), (u'InovanceTech', 3)]\n",
        "\n",
        "[(u'machinelearning', 59), (u'MachineLearning', 40), (u'bigdata', 16), (u'BigData', 12), (u'DeepLearning', 9), (u'textanalysis', 7), (u'DataScience', 7), (u'SVM', 5), (u'Analytics', 5), (u'Statistics', 4)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bonus Question: hashtags most common between #machinelearning and #datascience\n",
      "ml_hashtags_set = set([hashtag for hashtag in ml_hashtags])\n",
      "ds_hashtags_set = set([hashtag for hashtag in hashtags])\n",
      "b_common_hashtags = ml_hashtags_set.intersection(ds_hashtags_set)\n",
      "b_common_hashtags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "{u'Analytics',\n",
        " u'BigData',\n",
        " u'Data',\n",
        " u'DataScience',\n",
        " u'MachineLearning',\n",
        " u'Statistics',\n",
        " u'analytics',\n",
        " u'bigdata',\n",
        " u'math',\n",
        " u'python',\n",
        " u'statistics'}"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bonus Question: Search most popular data science hashtags; determing trending topics across it.\n",
      "from collections import Counter\n",
      "for item in [words, hashtags]:\n",
      "    ch = Counter(item)\n",
      "    mc = ch.most_common()\n",
      "    print mc[:10]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'RT', 78), (u'#DataScience', 43), (u'#datascience', 40), (u'#BigData', 30), (u'the', 28), (u'in', 22), (u'and', 20), (u'#bigdata', 20), (u'Data', 18), (u'via', 17)]\n",
        "[(u'DataScience', 60), (u'datascience', 40), (u'BigData', 34), (u'bigdata', 20), (u'Analytics', 14), (u'design', 9), (u'visualization', 9), (u'UX', 9), (u'rstats', 5), (u'KDD', 3)]\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bonus Question: Search most prolific screen_names for data science and find out who they are\n",
      "# We have screen names already for 'Data Science', but now we need to look up the actual profile name\n",
      "query_results = twitter_api.users.lookup(screen_name=','.join(screen_names))\n",
      "names = [query_item[\"name\"] for query_item in query_results]\n",
      "names[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "[u'Tony Ojeda',\n",
        " u'Kirk Borne',\n",
        " u'Booz Allen Hamilton',\n",
        " u'Daniel Tunkelang',\n",
        " u'Mike Martino',\n",
        " u'Nick Evans',\n",
        " u'Said...r.Zacarias.r',\n",
        " u'Bloomberg LP',\n",
        " u'Analytics Institute',\n",
        " u'AMANDA CHAN']"
       ]
      }
     ],
     "prompt_number": 51
    }
   ],
   "metadata": {}
  }
 ]
}