{
 "metadata": {
  "name": "",
  "signature": "sha256:8190c19496a060bb1c10aee469daf2eaa117288308ff8d44a4a856fbf38c25fd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GA Data Science 10 (DAT10) - Lab 12\n",
      "\n",
      "### Recommendation Systems\n",
      "\n",
      "Francesco Mosconi\n",
      "\n",
      "### Today\n",
      "\n",
      "1. Simple similarity based recommendation system\n",
      "2. Recsys\n",
      "3. Optional (yhat)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Similarity based Recommendation System: Beers\n",
      "\n",
      "\n",
      "Let's build a recommendation system to recommend types of beers based on user reviews"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usual imports (numpy, pandas)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First of all let's get the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! curl -O https://s3.amazonaws.com/demo-datasets/beer_reviews.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0 27.3M    0 35642    0     0  42273      0  0:11:19 --:--:--  0:11:19 42279"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  1 27.3M    1  463k    0     0   225k      0  0:02:04  0:00:02  0:02:02  225k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  3 27.3M    3  947k    0     0   333k      0  0:01:23  0:00:02  0:01:21  333k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  4 27.3M    4 1320k    0     0   343k      0  0:01:21  0:00:03  0:01:18  343k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  5 27.3M    5 1678k    0     0   346k      0  0:01:20  0:00:04  0:01:16  346k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  7 27.3M    7 2000k    0     0   342k      0  0:01:21  0:00:05  0:01:16  393k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  7 27.3M    7 2222k    0     0   324k      0  0:01:26  0:00:06  0:01:20  367k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  9 27.3M    9 2765k    0     0   349k      0  0:01:20  0:00:07  0:01:13  357k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 27.3M   10 3055k    0     0   345k      0  0:01:21  0:00:08  0:01:13  347k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 27.3M   12 3395k    0     0   344k      0  0:01:21  0:00:09  0:01:12  343k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 13 27.3M   13 3785k    0     0   348k      0  0:01:20  0:00:10  0:01:10  355k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 14 27.3M   14 4143k    0     0   337k      0  0:01:23  0:00:12  0:01:11  353k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 14 27.3M   14 4160k    0     0   303k      0  0:01:32  0:00:13  0:01:19  240k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 14 27.3M   14 4160k    0     0   282k      0  0:01:39  0:00:14  0:01:25  187k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 14 27.3M   14 4160k    0     0   275k      0  0:01:41  0:00:15  0:01:26  145k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 15 27.3M   15 4279k    0     0   270k      0  0:01:43  0:00:15  0:01:28   98k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 16 27.3M   16 4551k    0     0   270k      0  0:01:43  0:00:16  0:01:27 91701"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 17 27.3M   17 4993k    0     0   279k      "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  0:01:40  0:00:17  0:01:23  202k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 19 27.3M   19 5383k    0     0   285k      0  0:01:38  0:00:18  0:01:20  297k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 20 27.3M   20 5690k    0     0   286k      0  0:01:37  0:00:19  0:01:18  322k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 21 27.3M   21 6030k    0     0   289k      0  0:01:36  0:00:20  0:01:16  350k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 22 27.3M   22 6387k    0     0   292k      0  0:01:35  0:00:21  0:01:14  365k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 24 27.3M   24 6795k    0     0   296k      0  0:01:34  0:00:22  0:01:12  355k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 26 27.3M   26 7305k    0     0   306k      0  0:01:31  0:00:23  0:01:08  384k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 27 27.3M   27 7678k    0     0   308k      0  0:01:30  0:00:24  0:01:06  397k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 28 27.3M   28 8086k    0     0   312k      0  0:01:29  0:00:25  0:01:04  409k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 30 27.3M   30 8511k    0     0   316k      0  0:01:28  0:00:26  0:01:02  425k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 31 27.3M   31 8920k    0     0   320k      0  0:01:27  0:00:27  0:01:00  430k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 33 27.3M   33 9345k    0     0   324k      0  0:01:26  0:00:28  0:00:58  407k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 35 27.3M   35 9820k    0     0   329k      0  0:01:25  0:00:29  0:00:56  429k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 36 27.3M   36 10.0M    0     0   332k      0  0:01:24  0:00:30  0:00:54  434k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 38 27.3M   38 10.4M    0     0   336k      0  0:01:23  0:00:31  0:00:52  443k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 39 27.3M   39 10.9M    0     0   340k      0  0:01:22  0:00:32  0:00:50  454k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 41 27.3M   41 11.3M    0     0   344k      0  0:01:21  0:00:33  0:00:48  465k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 43 27.3M   43 11.8M    0     0   348k      0  0:01:20  0:00:34  0:00:46  464k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 44 27.3M   44 12.3M    0     0   351k      0  0:01:19  0:00:35  0:00:44  472k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 46 27.3M   46 12.7M    0     0   355k      0  0:01:18  0:00:36  0:00:42  472k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 48 27.3M   48 13.2M    0     0   356k      0  0:01:18  0:00:37  0:00:41  460k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 49 27.3M   49 13.4M    0     0   355k      0  0:01:18  0:00:38  0:00:40  427k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 49 27.3M   49 13.6M    0     0   350k      0  0:01:19  0:00:39  0:00:40  363k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 27.3M   50 13.9M    0     0   348k      0  0:01:20  0:00:40  0:00:40  328k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 51 27.3M   51 14.2M    0     0   348k      0  0:01:20  0:00:41  0:00:39  296k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 53 27.3M   53 14.5M    0     0   348k      0  0:01:20  0:00:42  0:00:38  282k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 54 27.3M   54 14.9M    0     0   347k      0  0:01:20  0:00:43  0:00:37  287k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 55 27.3M   55 15.2M    0     0   348k      0  0:01:20  0:00:44  0:00:36  336k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 56 27.3M   56 15.5M    0     0   348k      0  0:01:20  0:00:45  0:00:35  340k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 57 27.3M   57 15.8M    0     0   344k      0  0:01:21  0:00:47  0:00:34  311k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 58 27.3M   58 16.0M    0     0   344k      0  0:01:21  0:00:47  0:00:34  308k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 60 27.3M   60 16.4M    0     0   344k      0  0:01:21  0:00:48  0:00:33  319k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 61 27.3M   61 16.8M    0     0   345k      0  0:01:21  0:00:49  0:00:32  319k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 62 27.3M   62 17.1M    0     0   345k      0  0:01:21  0:00:50  0:00:31  320k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 63 27.3M   63 17.4M    0     0   344k      0  0:01:21  0:00:51  0:00:30  352k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 64 27.3M   64 17.6M    0     0   341k      0  0:01:22  0:00:52  0:00:30  316k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 65 27.3M   65 17.8M    0     0   338k      0  0:01:22  0:00:53  0:00:29  279k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 65 27.3M   65 18.0M    0     0   336k      0  0:01:23  0:00:54  0:00:29  245k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 66 27.3M   66 18.3M    0     0   336k      0  0:01:23  0:00:55  0:00:28  244k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 68 27.3M   68 18.6M    0     0   336k      0  0:01:23  0:00:56  0:00:27  244k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 69 27.3M   69 18.9M    0     0   335k      0  0:01:23  0:00:57  0:00:26  267k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 69 27.3M   69 19.0M    0     0   331k      0  0:01:24  0:00:58  0:00:26  256k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 70 27.3M   70 19.2M    0     0   328k      0  0:01:25  0:00:59  0:00:26  237k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 70 27.3M   70 19.3M    0     0   325k      0  0:01:26  0:01:00  0:00:26  204k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 71 27.3M   71 19.5M    0     0   323k      0  0:01:26  0:01:01  0:00:25  176k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 71 27.3M   71 19.7M    0     0   320k      0  0:01:27  0:01:02  0:00:25  156k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 72 27.3M   72 19.8M    0     0   317k      0  0:01:28  0:01:03  0:00:25  149k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 72 27.3M   72 19.9M    0     0   314k      0  0:01:29  0:01:04  0:00:25  150k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 73 27.3M   73 20.0M    0     0   312k      0  0:01:29  0:01:05  0:00:24  153k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 74 27.3M   74 20.2M    0     0   310k      0  0:01:30  0:01:06  0:00:24  153k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 74 27.3M   74 20.4M    0     0   309k      0  0:01:30  0:01:07  0:00:23  159k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 75 27.3M   75 20.7M    0     0   308k      0  0:01:30  0:01:08  0:00:22  194k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 76 27.3M   76 21.0M    0     0   308k      0  0:01:30  0:01:09  0:00:21  227k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 77 27.3M   77 21.2M    0     0   307k      0  0:01:31  0:01:10  0:00:21 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 244k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 78 27.3M   78 21.5M    0     0   307k      0  0:01:31  0:01:11  0:00:20  271k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 80 27.3M   80 21.9M    0     0   308k      0  0:01:30  0:01:12  0:00:18  304k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 81 27.3M   81 22.3M    0     0   309k      0  0:01:30  0:01:13  0:00:17  321k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 82 27.3M   82 22.6M    0     0   309k      0  0:01:30  0:01:14  0:00:16  319k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 83 27.3M   83 22.8M    0     0   307k      0  0:01:31  0:01:16  0:00:15  312k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 84 27.3M   84 23.0M    0     0   307k      0  0:01:31  0:01:16  0:00:15  306k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 85 27.3M   85 23.3M    0     0   306k      0  0:01:31  0:01:17  0:00:14  274k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 85 27.3M   85 23.4M    0     0   304k      0  0:01:31  0:01:18  0:00:13  241k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 86 27.3M   86 23.6M    0     0   303k      0  0:01:32  0:01:19  0:00:13  217k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 87 27.3M   87 23.8M    0     0   301k      0  0:01:32  0:01:20  0:00:12  207k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 87 27.3M   87 24.0M    0     0   300k      0  0:01:33  0:01:21  0:00:12  192k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 88 27.3M   88 24.2M    0     0   299k      0  0:01:33  0:01:22  0:00:11  193k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 90 27.3M   90 24.6M    0     0   301k      0  0:01:33  0:01:23  0:00:10  238k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 91 27.3M   91 25.1M    0     0   303k      0  0:01:32  0:01:24  0:00:08  295k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 93 27.3M   93 25.5M    0     0   304k      0  0:01:32  0:01:25  0:00:07  342k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 94 27.3M   94 25.9M    0     0   306k      0  0:01:31  0:01:26  0:00:05  396k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 96 27.3M   96 26.4M    0     0   308k      0  0:01:30  0:01:27  0:00:03  453k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 97 27.3M   97 26.7M    0     0   308k      0  0:01:31  0:01:29  0:00:02  420k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 98 27.3M   98 26.9M    0     0   306k      0  0:01:31  0:01:29  0:00:02  369k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 99 27.3M   99 27.1M    0     0   306k      0  0:01:31  0:01:30  0:00:01  338k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 27.3M  100 27.3M    0     0   305k      0  0:01:31  0:01:31 --:--:--  298k\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import data in a pandas dataframe called \"allbeers\". Use the compression keyword"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allbeers = pd.read_csv(\"beer_reviews.tar.gz\", compression='gzip')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "CParserError",
       "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mCParserError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-093d352f503c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mallbeers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beer_reviews.tar.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gzip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[0;32m    450\u001b[0m                     infer_datetime_format=infer_datetime_format)\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m _parser_defaults = {\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    693\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skip_footer not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:7145)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:7369)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:7978)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:7852)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32m/opt/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:19591)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mCParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allbeers.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's restrict this to the top 250 beers. Use the value_counts() method select the top 250 beers.\n",
      "Assign the selected beers to a dataset called df"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 250\n",
      "top_n = allbeers.beer_name.value_counts().index[:n]\n",
      "df = allbeers[allbeers.beer_name.isin(top_n)]\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How big is this dataset?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Pivot Table"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aggregate the data in a pivot table using the pivot_table method. Display the mean review_overall for each beer_name aggregating the review_overall values by review_profilename. Use the mean as aggregator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.pivot_table?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_wide = pd.pivot_table(df, values=['review_overall'], \n",
      "                         index=['beer_name', 'review_profilename'],                     \n",
      "                         aggfunc=np.mean).unstack()\n",
      "df_wide.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Display the head of the pivot table, but only for 5 users (columns are users)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_wide.ix[0:5, 0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Discussion: what do you notice in this table?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Data munging\n",
      "Set Nans to zero"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# perphaps not filling with '0' but average or another data point to prevent skew\n",
      "df_wide = df_wide.fillna(0)\n",
      "df_wide.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that columns are users"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_wide.columns[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that rows are beers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.Series(df_wide.index[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Calculate distance between beers\n",
      "\n",
      "We're going to use cosine_similarity from scikit-learn to compute the distance between all beers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.metrics.pairwise import manhattan_distances\n",
      "from sklearn.metrics.pairwise import euclidean_distances"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Apply cosine similarity to df_wide to calculate pairwise distances"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dists = cosine_similarity(df_wide)\n",
      "dists.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Discussion: what type of object is dists?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convert dists to a Pandas DataFrame, use the index as column index as well (distances are a square matrix)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dists = pd.DataFrame(dists, columns = df_wide.index, index=df_wide.index)\n",
      "dists.ix[0:10, 0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Select some beers and look their distances to other beers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beers_i_like = ['Sierra Nevada Pale Ale',\n",
      "                '120 Minute IPA',\n",
      "                'Allagash White']\n",
      "dists[beers_i_like].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sum the distances of my favourite beers by row, to have one distance from each beer in the sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beers_summed = dists[beers_i_like].apply(lambda row: np.sum(row), axis=1)\n",
      "#beers_summed = np.sum(dists[beers_i_like], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Performance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optional: which one is faster? use ```%timeit``` to check"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit dists[beers_i_like].apply(lambda row: np.sum(row), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit np.sum(dists[beers_i_like], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit dists[beers_i_like].sum(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Ranking"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beers_summed = beers_summed.order(ascending=False)\n",
      "beers_summed.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sort summed beers from best to worse"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filter out the beers used as input and transform to list"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ranked_beers = beers_summed.index[beers_summed.index.isin(beers_i_like)==False]\n",
      "ranked_beers = ranked_beers.tolist()\n",
      "ranked_beers[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function that does what we just did for an arbitrary input list of beers. it should also receive the maximum number of beers requested n as optional parameter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_similar_beers(beers, n=None):\n",
      "    beers = [beer for beer in beers if beer in dists.columns]\n",
      "    beers_summed = dists[beers].apply(lambda row: np.sum(row), axis=1)\n",
      "    beers_summed = beers_summed.order(ascending=False)\n",
      "    ranked_beers = beers_summed.index[beers_summed.index.isin(beers)==False]\n",
      "    ranked_beers = ranked_beers.tolist()\n",
      "    if n is None:\n",
      "        return ranked_beers\n",
      "    else:\n",
      "        return ranked_beers[:n]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test your function. Find the 10 beers most similar to \"120 Minute IPA\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beer_list = [\"120 Minute IPA\"]\n",
      "top_list = get_similar_beers(beer_list, 10)\n",
      "print top_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cool, let's try again with the 10 beers most similar to [\"Coors Light\", \"Bud Light\", \"Amstel Light\"]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beer_list = [\"Coors Light\", \"Bud Light\", \"Amstel Light\"]\n",
      "top_list = get_similar_beers(beer_list, 10)\n",
      "print top_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optional: register an account on yhat and deploy your model following the instructions [here](https://docs.yhathq.com/python/examples/beer-recommender) and [here](http://nbviewer.ipython.org/gist/glamp/20a18d52c539b87de2af)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Recsys\n",
      "\n",
      "A python library for implementing a recommender system"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "##install python-recsys\n",
      "\n",
      "### first install dependencies\n",
      "\n",
      "pip install csc-pysparse networkx divisi2\n",
      "\n",
      "### then install recsys\n",
      "git clone https://github.com/python-recsys/python-recsys.git\n",
      "cd python-recsys/\n",
      "\n",
      "python setup.py install\n",
      "\"\"\"\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load recsys.algotihm, set VERBOSE = True import SVD class"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import recsys.algorithm\n",
      "recsys.algorithm.VERBOSE = True\n",
      "from recsys.algorithm.factorize import SVD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at the files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! ls movielens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "movies.dat  ratings.dat  README  users.dat\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import 'movies.dat' to a 'movies' pandas dataframe. Make sure you name the columns, use the correct separator and define the index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies = pd.read_table('movielens/movies.dat', sep='::', \n",
      "                       names= ['ITEMID', 'Title', 'Genres'], index_col= 'ITEMID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Title</th>\n",
        "      <th>Genres</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ITEMID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>                   Toy Story (1995)</td>\n",
        "      <td>  Animation|Children's|Comedy</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>                     Jumanji (1995)</td>\n",
        "      <td> Adventure|Children's|Fantasy</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>            Grumpier Old Men (1995)</td>\n",
        "      <td>               Comedy|Romance</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>           Waiting to Exhale (1995)</td>\n",
        "      <td>                 Comedy|Drama</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> Father of the Bride Part II (1995)</td>\n",
        "      <td>                       Comedy</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                                     Title                        Genres\n",
        "ITEMID                                                                  \n",
        "1                         Toy Story (1995)   Animation|Children's|Comedy\n",
        "2                           Jumanji (1995)  Adventure|Children's|Fantasy\n",
        "3                  Grumpier Old Men (1995)                Comedy|Romance\n",
        "4                 Waiting to Exhale (1995)                  Comedy|Drama\n",
        "5       Father of the Bride Part II (1995)                        Comedy"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import 'ratings.dat' to a 'ratings' pandas dataframe. Make sure you name the columns, use the correct separator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings = pd.read_table('movielens/ratings.dat', sep='::', names= ['UserID','MovieID','Rating','Timestamp'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>UserID</th>\n",
        "      <th>MovieID</th>\n",
        "      <th>Rating</th>\n",
        "      <th>Timestamp</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1193</td>\n",
        "      <td> 5</td>\n",
        "      <td> 978300760</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td>  661</td>\n",
        "      <td> 3</td>\n",
        "      <td> 978302109</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td>  914</td>\n",
        "      <td> 3</td>\n",
        "      <td> 978301968</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 3408</td>\n",
        "      <td> 4</td>\n",
        "      <td> 978300275</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1</td>\n",
        "      <td> 2355</td>\n",
        "      <td> 5</td>\n",
        "      <td> 978824291</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "   UserID  MovieID  Rating  Timestamp\n",
        "0       1     1193       5  978300760\n",
        "1       1      661       3  978302109\n",
        "2       1      914       3  978301968\n",
        "3       1     3408       4  978300275\n",
        "4       1     2355       5  978824291"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize an SVD instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svd = SVD()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Populate it with the data from the ratings dataset, using the built in load_data method"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svd.load_data(filename='./movielens/ratings.dat', sep='::', format={'col':0, 'row':1, 'value':2, 'ids': int})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading ./movielens/ratings.dat\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".|\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute SVD\n",
      "\n",
      "$M=U \\Sigma V^T$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k = 100\n",
      "svd.compute(k=k, min_values=10, pre_normalize=None, mean_center=True, post_normalize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating matrix (1000209 tuples)\n",
        "Matrix density is: 4.4684%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Updating matrix: squish to at least 10 values\n",
        "Computing svd k=100, min_values=10, pre_normalize=None, mean_center=True, post_normalize=True\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[WARNING] mean_center is True. svd.similar(...) might return nan's. If so, then do svd.compute(..., mean_center=False)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "you can also save the output SVD model (in a zip file)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# svd.compute(k=k, min_values=10, pre_normalize=None, mean_center=True, post_normalize=True, savefile='/tmp/movielens')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reload a saved model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# svd2 = SVD(filename='/tmp/movielens')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find the ITEMID number for \"Toy Story (1995)\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies[movies.Title == \"Toy Story (1995)\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Title</th>\n",
        "      <th>Genres</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ITEMID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Toy Story (1995)</td>\n",
        "      <td> Animation|Children's|Comedy</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "                   Title                       Genres\n",
        "ITEMID                                               \n",
        "1       Toy Story (1995)  Animation|Children's|Comedy"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find the ITEMID number for \"Bug's Life, A (1998)\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies[movies.Title == \"Bug's Life, A (1998)\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Title</th>\n",
        "      <th>Genres</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ITEMID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2355</th>\n",
        "      <td> Bug's Life, A (1998)</td>\n",
        "      <td> Animation|Children's|Comedy</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "                       Title                       Genres\n",
        "ITEMID                                                   \n",
        "2355    Bug's Life, A (1998)  Animation|Children's|Comedy"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute similarity between the two movies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ITEMID1 = 1    # Toy Story (1995)\n",
      "ITEMID2 = 2355 # A bug's life (1998)\n",
      "print svd.similarity(ITEMID1, ITEMID2)\n",
      "# print svd2.similarity(ITEMID1, ITEMID2) to check"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.677069366773\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get movies similar to Toy Story"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "similar_to_toy_story = svd.similar(ITEMID1)\n",
      "similar_to_toy_story"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[(1, 0.99999999999999978),\n",
        " (3114, 0.87060391051017305),\n",
        " (2355, 0.67706936677314977),\n",
        " (588, 0.58073514967544992),\n",
        " (595, 0.46031829709744226),\n",
        " (1907, 0.44589398718134982),\n",
        " (364, 0.42908159895577563),\n",
        " (2081, 0.42566581277822413),\n",
        " (3396, 0.42474056361934953),\n",
        " (2761, 0.40439361857576017)]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Predict rating for a given user and movie, $\\hat{r}_{ui}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#res = pd.DataFrame(movies[movies.index.isin(zip(*similar_to_toy_story)[0])].Title)\n",
      "#res['ratings'] = zip(*similar_to_toy_story)[1]\n",
      "#res.sort('ratings', ascending=False)\n",
      "#res\n",
      "\n",
      "movies[movies.index.isin(zip(*similar_to_toy_story)[0])]\n",
      "#np.array(similar_to_toy_story)[:,0].astype(int)\n",
      "#zip(*similar_to_toy_story) is equivalent to transpose"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Title</th>\n",
        "      <th>Genres</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ITEMID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1   </th>\n",
        "      <td>            Toy Story (1995)</td>\n",
        "      <td>                 Animation|Children's|Comedy</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>364 </th>\n",
        "      <td>       Lion King, The (1994)</td>\n",
        "      <td>                Animation|Children's|Musical</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>588 </th>\n",
        "      <td>              Aladdin (1992)</td>\n",
        "      <td>         Animation|Children's|Comedy|Musical</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>595 </th>\n",
        "      <td> Beauty and the Beast (1991)</td>\n",
        "      <td>                Animation|Children's|Musical</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1907</th>\n",
        "      <td>                Mulan (1998)</td>\n",
        "      <td>                        Animation|Children's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2081</th>\n",
        "      <td>  Little Mermaid, The (1989)</td>\n",
        "      <td> Animation|Children's|Comedy|Musical|Romance</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2355</th>\n",
        "      <td>        Bug's Life, A (1998)</td>\n",
        "      <td>                 Animation|Children's|Comedy</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2761</th>\n",
        "      <td>      Iron Giant, The (1999)</td>\n",
        "      <td>                        Animation|Children's</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3114</th>\n",
        "      <td>          Toy Story 2 (1999)</td>\n",
        "      <td>                 Animation|Children's|Comedy</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3396</th>\n",
        "      <td>    Muppet Movie, The (1979)</td>\n",
        "      <td>                           Children's|Comedy</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "                              Title  \\\n",
        "ITEMID                                \n",
        "1                  Toy Story (1995)   \n",
        "364           Lion King, The (1994)   \n",
        "588                  Aladdin (1992)   \n",
        "595     Beauty and the Beast (1991)   \n",
        "1907                   Mulan (1998)   \n",
        "2081     Little Mermaid, The (1989)   \n",
        "2355           Bug's Life, A (1998)   \n",
        "2761         Iron Giant, The (1999)   \n",
        "3114             Toy Story 2 (1999)   \n",
        "3396       Muppet Movie, The (1979)   \n",
        "\n",
        "                                             Genres  \n",
        "ITEMID                                               \n",
        "1                       Animation|Children's|Comedy  \n",
        "364                    Animation|Children's|Musical  \n",
        "588             Animation|Children's|Comedy|Musical  \n",
        "595                    Animation|Children's|Musical  \n",
        "1907                           Animation|Children's  \n",
        "2081    Animation|Children's|Comedy|Musical|Romance  \n",
        "2355                    Animation|Children's|Comedy  \n",
        "2761                           Animation|Children's  \n",
        "3114                    Animation|Children's|Comedy  \n",
        "3396                              Children's|Comedy  "
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MIN_RATING = 0.0\n",
      "MAX_RATING = 5.0\n",
      "ITEMID = 1\n",
      "USERID = 1\n",
      "svd.predict(ITEMID, USERID, MIN_RATING, MAX_RATING)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "5.0"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svd.get_matrix().value(ITEMID, USERID)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "5.0"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recommend non rated movies to a user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svd.recommend(USERID, is_row=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[(2028, 5.4018452642332546),\n",
        " (527, 5.3498144196809516),\n",
        " (2905, 5.2133848204673132),\n",
        " (318, 5.2052108435955446),\n",
        " (1193, 5.1942189963876562),\n",
        " (3114, 5.1753939214583697),\n",
        " (1, 5.1714259073839521),\n",
        " (2019, 5.1037438278754719),\n",
        " (1178, 5.0962756861446641),\n",
        " (1207, 5.090305272922329)]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which users should see Toy Story? (e.g. which users -that have not rated Toy Story- would give it a high rating?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svd.recommend(ITEMID)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "[(869, 6.8215500393190904),\n",
        " (4086, 6.2667649038936908),\n",
        " (549, 6.2394061595542869),\n",
        " (1343, 6.2163075783431427),\n",
        " (1586, 6.039893928886932),\n",
        " (840, 5.9616632765170472),\n",
        " (1676, 5.896233772781037),\n",
        " (4595, 5.88945710113423),\n",
        " (2691, 5.8735094161364714),\n",
        " (2665, 5.8498694241604259)]"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find out more here: [https://github.com/ocelma/python-recsys](https://github.com/ocelma/python-recsys)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}